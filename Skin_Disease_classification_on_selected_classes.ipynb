{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import shutil\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "PCvd_wlVSd6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLjZYxCjSRxv",
        "outputId": "ce5a807b-c816-45a1-e3fa-8adb2521a2c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shubhamgoel27/dermnet?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.72G/1.72G [00:10<00:00, 184MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/shubhamgoel27/dermnet/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download Dataset\n",
        "path = kagglehub.dataset_download(\"shubhamgoel27/dermnet\")\n",
        "print(\"Dataset downloaded to:\", path)\n",
        "\n",
        "train_dir = os.path.join(path, \"train\")\n",
        "test_dir = os.path.join(path, \"test\")\n",
        "train_target_dir = \"/distributed_train\"\n",
        "test_target_dir = \"/distributed_test\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kagglehub\n",
        "\n",
        "# Download Dataset\n",
        "path = kagglehub.dataset_download(\"shubhamgoel27/dermnet\")\n",
        "print(\"Dataset downloaded to:\", path)\n",
        "\n",
        "train_dir = os.path.join(path, \"train\")\n",
        "test_dir = os.path.join(path, \"test\")\n",
        "print(\"Train Directory:\", train_dir)\n",
        "print(\"Test Directory:\", test_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5U8tDVmTKZI",
        "outputId": "9f25684f-cb92-48ba-abf6-17a5383a0cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/shubhamgoel27/dermnet/versions/1\n",
            "Train Directory: /root/.cache/kagglehub/datasets/shubhamgoel27/dermnet/versions/1/train\n",
            "Test Directory: /root/.cache/kagglehub/datasets/shubhamgoel27/dermnet/versions/1/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"shubhamgoel27/dermnet\")\n",
        "print(\"Dataset downloaded to:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAO4C1J9UB8S",
        "outputId": "3eed11d7-759b-4ac1-e7b0-ed5b9a543b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/shubhamgoel27/dermnet/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy dataset to a simpler location in the working directory\n",
        "new_path = \"/content/dermnet_dataset\"\n",
        "!cp -r {path} {new_path}\n",
        "\n",
        "# Update train and test paths\n",
        "train_dir = os.path.join(new_path, \"train\")\n",
        "test_dir = os.path.join(new_path, \"test\")\n",
        "\n",
        "print(\"New Train Directory:\", train_dir)\n",
        "print(\"New Test Directory:\", test_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcHp_4OkUS3v",
        "outputId": "7350e366-56c4-4a6a-b96e-85e00abb05f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Train Directory: /content/dermnet_dataset/train\n",
            "New Test Directory: /content/dermnet_dataset/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pandas as pd\n",
        "\n",
        "# # Selected disease classes\n",
        "# selected_classes = [\n",
        "#     \"Psoriasis pictures Lichen Planus and related diseases\",\n",
        "#     \"Tinea Ringworm Candidiasis and other Fungal Infections\",\n",
        "#     \"Melanoma Skin Cancer Nevi and Moles\",\n",
        "#     \"Nail Fungus and other Nail Disease\",\n",
        "#     \"Acne and Rosacea Photos\",\n",
        "#     \"Warts Molluscum and other Viral Infections\",\n",
        "#     \"Seborrheic Keratoses and other Benign Tumors\"\n",
        "# ]\n",
        "\n"
      ],
      "metadata": {
        "id": "OXt31tnyUjQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Paths for train and test directories\n",
        "# train_dir = \"/content/dermnet_dataset/train\"\n",
        "# test_dir = \"/content/dermnet_dataset/train/test\"\n",
        "\n",
        "# # Function to create a DataFrame for a given directory\n",
        "# def create_dataframe(base_dir, selected_classes):\n",
        "#     data = []\n",
        "#     for class_name in selected_classes:\n",
        "#         class_path = os.path.join(base_dir, class_name)\n",
        "#         if os.path.exists(class_path):\n",
        "#             for image_name in os.listdir(class_path):\n",
        "#                 image_path = os.path.join(class_path, image_name)\n",
        "#                 data.append({\"image_path\": image_path, \"label\": class_name})\n",
        "#     return pd.DataFrame(data)\n",
        "\n",
        "# # Create DataFrames for train and test folders\n",
        "# train_df = create_dataframe(train_dir, selected_classes)\n",
        "# test_df = create_dataframe(test_dir, selected_classes)\n",
        "\n",
        "# # Print the head of both DataFrames\n",
        "# print(\"Train DataFrame Head:\")\n",
        "# print(train_df.head())\n",
        "\n",
        "# print(\"\\nTest DataFrame Head:\")\n",
        "# print(test_df.head())"
      ],
      "metadata": {
        "id": "hAL1F4-TVa5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Paths for train and test directories\n",
        "train_dir = \"/content/dermnet_dataset/train\"\n",
        "test_dir = \"/content/dermnet_dataset/test\"\n",
        "\n",
        "# Selected classes\n",
        "selected_classes = [\n",
        "    \"Psoriasis pictures Lichen Planus and related diseases\",\n",
        "    \"Tinea Ringworm Candidiasis and other Fungal Infections\",\n",
        "    \"Melanoma Skin Cancer Nevi and Moles\",\n",
        "    \"Nail Fungus and other Nail Disease\",\n",
        "    \"Acne and Rosacea Photos\",\n",
        "    \"Warts Molluscum and other Viral Infections\",\n",
        "    \"Seborrheic Keratoses and other Benign Tumors\"\n",
        "]\n",
        "\n",
        "# Function to simplify class names\n",
        "def simplify_class_name(class_name):\n",
        "    # Define a mapping for simplification\n",
        "    simplification_mapping = {\n",
        "        \"Psoriasis pictures Lichen Planus and related diseases\": \"Psoriasis\",\n",
        "        \"Tinea Ringworm Candidiasis and other Fungal Infections\": \"Fungal Infections\",\n",
        "        \"Melanoma Skin Cancer Nevi and Moles\": \"Melanoma\",\n",
        "        \"Nail Fungus and other Nail Disease\": \"Nail Fungus\",\n",
        "        \"Acne and Rosacea Photos\": \"Acne\",\n",
        "        \"Warts Molluscum and other Viral Infections\": \"Warts\",\n",
        "        \"Seborrheic Keratoses and other Benign Tumors\": \"Benign Tumors\"\n",
        "    }\n",
        "    return simplification_mapping.get(class_name, class_name)  # Default to original if not mapped\n",
        "\n",
        "# Function to create a DataFrame for a given directory\n",
        "def create_dataframe(base_dir, selected_classes):\n",
        "    data = []\n",
        "    for class_name in selected_classes:\n",
        "        class_path = os.path.join(base_dir, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            for image_name in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_name)\n",
        "                simplified_class_name = simplify_class_name(class_name)\n",
        "                data.append({\"image_path\": image_path, \"label\": class_name, \"class_name\": simplified_class_name})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Create DataFrames for train and test folders\n",
        "train_df = create_dataframe(train_dir, selected_classes)\n",
        "test_df = create_dataframe(test_dir, selected_classes)\n",
        "\n",
        "# Print the head of both DataFrames\n",
        "print(\"Train DataFrame Head:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nTest DataFrame Head:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_xxb1ojWEXm",
        "outputId": "b5cc7df1-e9ad-4c5f-f72b-e7d8f6ac524f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame Head:\n",
            "                                          image_path  \\\n",
            "0  /content/dermnet_dataset/train/Psoriasis pictu...   \n",
            "1  /content/dermnet_dataset/train/Psoriasis pictu...   \n",
            "2  /content/dermnet_dataset/train/Psoriasis pictu...   \n",
            "3  /content/dermnet_dataset/train/Psoriasis pictu...   \n",
            "4  /content/dermnet_dataset/train/Psoriasis pictu...   \n",
            "\n",
            "                                               label class_name  \n",
            "0  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "1  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "2  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "3  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "4  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "\n",
            "Test DataFrame Head:\n",
            "                                          image_path  \\\n",
            "0  /content/dermnet_dataset/test/Psoriasis pictur...   \n",
            "1  /content/dermnet_dataset/test/Psoriasis pictur...   \n",
            "2  /content/dermnet_dataset/test/Psoriasis pictur...   \n",
            "3  /content/dermnet_dataset/test/Psoriasis pictur...   \n",
            "4  /content/dermnet_dataset/test/Psoriasis pictur...   \n",
            "\n",
            "                                               label class_name  \n",
            "0  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "1  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "2  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "3  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n",
            "4  Psoriasis pictures Lichen Planus and related d...  Psoriasis  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import cv2\n",
        "\n",
        "# # Function to display the first 10 images from a DataFrame\n",
        "# def display_images(dataframe, title, num_images=10):\n",
        "#     plt.figure(figsize=(15, 5))\n",
        "#     for i in range(min(num_images, len(dataframe))):\n",
        "#         img_path = dataframe.iloc[i][\"image_path\"]\n",
        "#         img = cv2.imread(img_path)\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for displaying\n",
        "#         plt.subplot(2, 5, i + 1)  # Create a grid for displaying images (2 rows, 5 columns)\n",
        "#         plt.imshow(img)\n",
        "#         plt.title(dataframe.iloc[i][\"label\"], fontsize=8)\n",
        "#         plt.axis(\"off\")\n",
        "#     plt.suptitle(title, fontsize=16)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # Display the first 10 images in train_df\n",
        "# print(\"Displaying the first 10 images from the training dataset:\")\n",
        "# display_images(train_df, \"Train Dataset\")\n",
        "\n",
        "# # Display the first 10 images in test_df\n",
        "# print(\"Displaying the first 10 images from the test dataset:\")\n",
        "# display_images(test_df, \"Test Dataset\")\n"
      ],
      "metadata": {
        "id": "Lh6sBjMSVbww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"class_name\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "rjkoiRSFWfTo",
        "outputId": "e8acbf97-d314-41c2-8bbf-8f0c7023f11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class_name\n",
              "Psoriasis            1405\n",
              "Benign Tumors        1371\n",
              "Fungal Infections    1300\n",
              "Warts                1086\n",
              "Nail Fungus          1040\n",
              "Acne                  840\n",
              "Melanoma              463\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class_name</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Psoriasis</th>\n",
              "      <td>1405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Benign Tumors</th>\n",
              "      <td>1371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fungal Infections</th>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Warts</th>\n",
              "      <td>1086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nail Fungus</th>\n",
              "      <td>1040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acne</th>\n",
              "      <td>840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Melanoma</th>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"class_name\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "p0TYVWQXWrwM",
        "outputId": "1f9402d2-f9fb-43c8-eacc-6a5a1d704af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class_name\n",
              "Psoriasis            352\n",
              "Benign Tumors        343\n",
              "Fungal Infections    325\n",
              "Acne                 312\n",
              "Warts                272\n",
              "Nail Fungus          261\n",
              "Melanoma             116\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class_name</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Psoriasis</th>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Benign Tumors</th>\n",
              "      <td>343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fungal Infections</th>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acne</th>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Warts</th>\n",
              "      <td>272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nail Fungus</th>\n",
              "      <td>261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Melanoma</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# Define data augmentation transformations\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomRotation(15),     # Randomly rotate images by 15 degrees\n",
        "    transforms.RandomResizedCrop(224), # Randomly crop and resize to 224x224\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color\n",
        "    transforms.ToTensor(),             # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Define transformations for non-augmented data\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),     # Resize to 224x224\n",
        "    transforms.ToTensor(),             # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Custom Dataset Class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, selected_classes_for_augmentation):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame containing image paths and labels.\n",
        "            selected_classes_for_augmentation (list): List of class names to apply augmentation.\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.selected_classes = selected_classes_for_augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.dataframe.iloc[index]\n",
        "        image_path = row[\"image_path\"]\n",
        "        label = row[\"class_name\"]\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply augmentation only for selected classes\n",
        "        if label in self.selected_classes:\n",
        "            image = augmentation_transform(image)\n",
        "        else:\n",
        "            image = base_transform(image)\n",
        "\n",
        "        # Convert label to index for PyTorch compatibility\n",
        "        label_index = selected_classes.index(label)\n",
        "\n",
        "        return image, label_index\n",
        "\n",
        "# Define the selected classes for augmentation\n",
        "selected_classes = [\n",
        "    \"Psoriasis\",\n",
        "    \"Fungal Infections\",\n",
        "    \"Melanoma\",\n",
        "    \"Nail Fungus\",\n",
        "    \"Acne\",\n",
        "    \"Warts\",\n",
        "    \"Benign Tumors\"\n",
        "]\n",
        "selected_classes_for_augmentation = [\"Psoriasis\", \"Fungal Infections\", \"Melanoma\"]\n",
        "\n",
        "# Create datasets using train_df and test_df\n",
        "train_dataset = CustomDataset(train_df, selected_classes_for_augmentation)\n",
        "test_dataset = CustomDataset(test_df, selected_classes_for_augmentation)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Print dataset information\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n",
        "\n",
        "# Check the first few samples (optional)\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Batch size: {images.size()}, Labels: {labels}\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILc1t1jUYnfp",
        "outputId": "54ca1c58-aef1-43a0-9f53-8a1a1992e603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 7505\n",
            "Number of testing samples: 1981\n",
            "Batch size: torch.Size([64, 3, 224, 224]), Labels: tensor([1, 2, 3, 1, 0, 6, 5, 5, 6, 5, 4, 5, 2, 5, 6, 5, 1, 1, 1, 5, 0, 6, 0, 1,\n",
            "        6, 4, 1, 6, 4, 1, 0, 5, 3, 1, 1, 3, 6, 5, 3, 6, 4, 1, 4, 3, 5, 6, 0, 3,\n",
            "        3, 5, 5, 6, 0, 5, 5, 1, 3, 6, 5, 1, 4, 6, 0, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate number of images per class before augmentation\n",
        "def calculate_class_counts(dataframe, class_column=\"class_name\"):\n",
        "    return dataframe[class_column].value_counts()\n",
        "\n",
        "# Simulate the number of images after augmentation\n",
        "def calculate_effective_class_counts(dataframe, augmented_classes, multiplier=2):\n",
        "    class_counts = dataframe[\"class_name\"].value_counts()\n",
        "    effective_counts = class_counts.copy()\n",
        "\n",
        "    for cls in augmented_classes:\n",
        "        if cls in effective_counts.index:\n",
        "            effective_counts[cls] *= multiplier  # Multiply by the augmentation factor\n",
        "\n",
        "    return effective_counts\n",
        "\n",
        "# Calculate and print counts for train_df\n",
        "train_class_counts_before = calculate_class_counts(train_df)\n",
        "train_class_counts_after = calculate_effective_class_counts(train_df, selected_classes_for_augmentation)\n",
        "\n",
        "print(\"Training Dataset - Counts Before Augmentation:\")\n",
        "print(train_class_counts_before)\n",
        "\n",
        "print(\"\\nTraining Dataset - Effective Counts After Augmentation:\")\n",
        "print(train_class_counts_after)\n",
        "\n",
        "# Calculate and print counts for test_df\n",
        "test_class_counts_before = calculate_class_counts(test_df)\n",
        "test_class_counts_after = calculate_effective_class_counts(test_df, selected_classes_for_augmentation)\n",
        "\n",
        "print(\"\\nTesting Dataset - Counts Before Augmentation:\")\n",
        "print(test_class_counts_before)\n",
        "\n",
        "print(\"\\nTesting Dataset - Effective Counts After Augmentation:\")\n",
        "print(test_class_counts_after)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCsK3-kVZMfX",
        "outputId": "4cc8f6d9-5478-4eb6-b9c3-769004f5997e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset - Counts Before Augmentation:\n",
            "class_name\n",
            "Psoriasis            1405\n",
            "Benign Tumors        1371\n",
            "Fungal Infections    1300\n",
            "Warts                1086\n",
            "Nail Fungus          1040\n",
            "Acne                  840\n",
            "Melanoma              463\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Training Dataset - Effective Counts After Augmentation:\n",
            "class_name\n",
            "Psoriasis            2810\n",
            "Benign Tumors        1371\n",
            "Fungal Infections    2600\n",
            "Warts                1086\n",
            "Nail Fungus          1040\n",
            "Acne                  840\n",
            "Melanoma              926\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing Dataset - Counts Before Augmentation:\n",
            "class_name\n",
            "Psoriasis            352\n",
            "Benign Tumors        343\n",
            "Fungal Infections    325\n",
            "Acne                 312\n",
            "Warts                272\n",
            "Nail Fungus          261\n",
            "Melanoma             116\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing Dataset - Effective Counts After Augmentation:\n",
            "class_name\n",
            "Psoriasis            704\n",
            "Benign Tumors        343\n",
            "Fungal Infections    650\n",
            "Acne                 312\n",
            "Warts                272\n",
            "Nail Fungus          261\n",
            "Melanoma             232\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# balancing the minority classes"
      ],
      "metadata": {
        "id": "8bz8ZY5Ta-vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Define data augmentation transformations\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomRotation(15),     # Randomly rotate images by 15 degrees\n",
        "    transforms.RandomResizedCrop(224), # Randomly crop and resize to 224x224\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color\n",
        "    transforms.ToTensor(),             # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Define transformations for non-augmented data\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),     # Resize to 224x224\n",
        "    transforms.ToTensor(),             # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Custom Dataset Class\n",
        "class BalancedDataset(Dataset):\n",
        "    def __init__(self, dataframe, selected_classes_for_augmentation, target_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame containing image paths and labels.\n",
        "            selected_classes_for_augmentation (list): List of class names to apply augmentation.\n",
        "            target_size (int): The number of images to sample per class for balancing.\n",
        "        \"\"\"\n",
        "        self.data = []\n",
        "        self.selected_classes = selected_classes_for_augmentation\n",
        "        self.target_size = target_size\n",
        "        self.class_counts = dataframe[\"class_name\"].value_counts()\n",
        "\n",
        "        for class_name, count in self.class_counts.items():\n",
        "            class_samples = dataframe[dataframe[\"class_name\"] == class_name]\n",
        "\n",
        "            # Oversample or undersample to match the target size\n",
        "            if count < self.target_size:\n",
        "                sampled_df = class_samples.sample(n=self.target_size, replace=True)  # Oversample\n",
        "            else:\n",
        "                sampled_df = class_samples.sample(n=self.target_size, replace=False)  # Undersample\n",
        "\n",
        "            self.data.append(sampled_df)\n",
        "\n",
        "        self.data = pd.concat(self.data).reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        image_path = row[\"image_path\"]\n",
        "        label = row[\"class_name\"]\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply augmentation only for selected classes\n",
        "        if label in self.selected_classes:\n",
        "            image = augmentation_transform(image)\n",
        "        else:\n",
        "            image = base_transform(image)\n",
        "\n",
        "        # Convert label to index for PyTorch compatibility\n",
        "        label_index = selected_classes.index(label)\n",
        "\n",
        "        return image, label_index\n",
        "\n",
        "# Define the selected classes and target size for balancing\n",
        "selected_classes = [\n",
        "    \"Psoriasis\",\n",
        "    \"Fungal Infections\",\n",
        "    \"Melanoma\",\n",
        "    \"Nail Fungus\",\n",
        "    \"Acne\",\n",
        "    \"Warts\",\n",
        "    \"Benign Tumors\"\n",
        "]\n",
        "selected_classes_for_augmentation = [\"Psoriasis\", \"Fungal Infections\", \"Melanoma\"]\n",
        "\n",
        "# Target number of images per class\n",
        "target_size = max(train_df[\"class_name\"].value_counts())\n",
        "\n",
        "# Create balanced datasets using train_df and test_df\n",
        "train_balanced_dataset = BalancedDataset(train_df, selected_classes_for_augmentation, target_size)\n",
        "test_balanced_dataset = BalancedDataset(test_df, selected_classes_for_augmentation, target_size)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_balanced_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_balanced_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Print dataset information\n",
        "print(f\"Number of training samples (balanced): {len(train_balanced_dataset)}\")\n",
        "print(f\"Number of testing samples (balanced): {len(test_balanced_dataset)}\")\n",
        "\n",
        "# Check the class distribution after balancing\n",
        "train_class_counts_balanced = train_balanced_dataset.data[\"class_name\"].value_counts()\n",
        "test_class_counts_balanced = test_balanced_dataset.data[\"class_name\"].value_counts()\n",
        "\n",
        "print(\"\\nTraining Dataset - Counts After Balancing:\")\n",
        "print(train_class_counts_balanced)\n",
        "\n",
        "print(\"\\nTesting Dataset - Counts After Balancing:\")\n",
        "print(test_class_counts_balanced)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YiNG70TZiVw",
        "outputId": "5b6da23f-70c1-44e0-e612-b19e8fe04261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples (balanced): 9835\n",
            "Number of testing samples (balanced): 9835\n",
            "\n",
            "Training Dataset - Counts After Balancing:\n",
            "class_name\n",
            "Psoriasis            1405\n",
            "Benign Tumors        1405\n",
            "Fungal Infections    1405\n",
            "Warts                1405\n",
            "Nail Fungus          1405\n",
            "Acne                 1405\n",
            "Melanoma             1405\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing Dataset - Counts After Balancing:\n",
            "class_name\n",
            "Psoriasis            1405\n",
            "Benign Tumors        1405\n",
            "Fungal Infections    1405\n",
            "Acne                 1405\n",
            "Warts                1405\n",
            "Nail Fungus          1405\n",
            "Melanoma             1405\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET 34"
      ],
      "metadata": {
        "id": "vvJxtDvRSJVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Check if GPU is available; fall back to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load pre-trained ResNet-34 model\n",
        "model = models.resnet34(pretrained=True)\n",
        "\n",
        "# Modify the fully connected layer to match the number of classes\n",
        "num_classes = len(selected_classes)  # 7 classes\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Move the model to the selected device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define training and validation loops\n",
        "def train(model, train_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Progress bar for training\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for images, labels in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
        "\n",
        "            # Move data to the selected device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update running loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Update progress bar\n",
        "            tepoch.set_postfix(loss=running_loss / (total / train_loader.batch_size), accuracy=accuracy)\n",
        "\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "\n",
        "def validate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            # Move data to the selected device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Update running loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss / len(test_loader), accuracy\n",
        "\n",
        "\n",
        "# Train the model for 30 epochs\n",
        "num_epochs = 30\n",
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = validate(model, test_loader, criterion)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"resnet34_skin_disease_balanced.pth\")\n",
        "print(\"\\nModel saved as 'resnet34_skin_disease_balanced.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl9a48UCa8Zn",
        "outputId": "bc85ac95-baa9-44da-8197-986b788491a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 308/308 [01:39<00:00,  3.11batch/s, accuracy=54, loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9578, Validation Accuracy: 57.50%\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 308/308 [01:38<00:00,  3.14batch/s, accuracy=64.5, loss=0.831]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8669, Validation Accuracy: 62.52%\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 308/308 [01:37<00:00,  3.17batch/s, accuracy=69.1, loss=0.721]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8857, Validation Accuracy: 62.57%\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 308/308 [01:37<00:00,  3.17batch/s, accuracy=73, loss=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9187, Validation Accuracy: 61.99%\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 308/308 [01:37<00:00,  3.16batch/s, accuracy=76.4, loss=0.543]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8390, Validation Accuracy: 68.12%\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 308/308 [01:37<00:00,  3.15batch/s, accuracy=78, loss=0.496]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8888, Validation Accuracy: 67.62%\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 308/308 [01:37<00:00,  3.15batch/s, accuracy=79.9, loss=0.447]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9614, Validation Accuracy: 66.77%\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 308/308 [01:38<00:00,  3.14batch/s, accuracy=81.7, loss=0.402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9542, Validation Accuracy: 69.09%\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 308/308 [01:39<00:00,  3.08batch/s, accuracy=82.3, loss=0.386]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8487, Validation Accuracy: 71.30%\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 308/308 [01:40<00:00,  3.07batch/s, accuracy=82.9, loss=0.372]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9839, Validation Accuracy: 71.16%\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 308/308 [01:40<00:00,  3.07batch/s, accuracy=83.6, loss=0.359]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9012, Validation Accuracy: 69.62%\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 308/308 [01:40<00:00,  3.06batch/s, accuracy=84.8, loss=0.341]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8276, Validation Accuracy: 71.77%\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 308/308 [01:40<00:00,  3.06batch/s, accuracy=85.3, loss=0.321]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8935, Validation Accuracy: 72.49%\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 308/308 [01:40<00:00,  3.06batch/s, accuracy=84.6, loss=0.325]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9339, Validation Accuracy: 70.73%\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 308/308 [01:40<00:00,  3.07batch/s, accuracy=85.5, loss=0.315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9707, Validation Accuracy: 69.53%\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 308/308 [01:40<00:00,  3.06batch/s, accuracy=84.8, loss=0.331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0775, Validation Accuracy: 69.56%\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 308/308 [01:37<00:00,  3.15batch/s, accuracy=86.2, loss=0.306]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9692, Validation Accuracy: 71.12%\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 308/308 [01:38<00:00,  3.13batch/s, accuracy=86.3, loss=0.308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8785, Validation Accuracy: 72.41%\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 308/308 [01:38<00:00,  3.12batch/s, accuracy=86.4, loss=0.302]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9232, Validation Accuracy: 70.88%\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 308/308 [01:37<00:00,  3.15batch/s, accuracy=87.4, loss=0.278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1655, Validation Accuracy: 70.28%\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 308/308 [01:37<00:00,  3.16batch/s, accuracy=86.9, loss=0.278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9399, Validation Accuracy: 73.42%\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 308/308 [01:38<00:00,  3.13batch/s, accuracy=87.4, loss=0.274]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0363, Validation Accuracy: 72.61%\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 308/308 [01:37<00:00,  3.16batch/s, accuracy=86.2, loss=0.305]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2214, Validation Accuracy: 69.89%\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 308/308 [01:37<00:00,  3.15batch/s, accuracy=87.5, loss=0.279]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9628, Validation Accuracy: 73.49%\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 308/308 [01:37<00:00,  3.15batch/s, accuracy=88, loss=0.261]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0719, Validation Accuracy: 72.02%\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 308/308 [01:38<00:00,  3.14batch/s, accuracy=88.3, loss=0.258]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1123, Validation Accuracy: 71.95%\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 308/308 [01:37<00:00,  3.16batch/s, accuracy=88.1, loss=0.268]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0286, Validation Accuracy: 71.26%\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 308/308 [01:37<00:00,  3.16batch/s, accuracy=87.3, loss=0.278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9373, Validation Accuracy: 71.05%\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 308/308 [01:37<00:00,  3.16batch/s, accuracy=89.3, loss=0.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1520, Validation Accuracy: 72.52%\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 308/308 [01:37<00:00,  3.16batch/s, accuracy=89.2, loss=0.245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0536, Validation Accuracy: 72.37%\n",
            "\n",
            "Model saved as 'resnet34_skin_disease_balanced.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INCEPTION V3"
      ],
      "metadata": {
        "id": "6QiwDn9uSMnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if GPU is available; fall back to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define transformations for training and validation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize image to 299x299\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize image to 299x299\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset Class\n",
        "class BalancedDataset(Dataset):\n",
        "    def __init__(self, dataframe, selected_classes_for_augmentation, target_size):\n",
        "        self.data = []\n",
        "        self.selected_classes = selected_classes_for_augmentation\n",
        "        self.target_size = target_size\n",
        "        self.class_counts = dataframe[\"class_name\"].value_counts()\n",
        "\n",
        "        for class_name, count in self.class_counts.items():\n",
        "            class_samples = dataframe[dataframe[\"class_name\"] == class_name]\n",
        "\n",
        "            # Oversample or undersample to match the target size\n",
        "            if count < self.target_size:\n",
        "                sampled_df = class_samples.sample(n=self.target_size, replace=True)  # Oversample\n",
        "            else:\n",
        "                sampled_df = class_samples.sample(n=self.target_size, replace=False)  # Undersample\n",
        "\n",
        "            self.data.append(sampled_df)\n",
        "\n",
        "        self.data = pd.concat(self.data).reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        image_path = row[\"image_path\"]\n",
        "        label = row[\"class_name\"]\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply augmentation only for selected classes\n",
        "        if label in self.selected_classes:\n",
        "            image = train_transform(image)\n",
        "        else:\n",
        "            image = test_transform(image)\n",
        "\n",
        "        # Convert label to index for PyTorch compatibility\n",
        "        label_index = selected_classes.index(label)\n",
        "\n",
        "        return image, label_index\n",
        "\n",
        "\n",
        "# Define the selected classes and target size for balancing\n",
        "selected_classes = [\n",
        "    \"Psoriasis\",\n",
        "    \"Fungal Infections\",\n",
        "    \"Melanoma\",\n",
        "    \"Nail Fungus\",\n",
        "    \"Acne\",\n",
        "    \"Warts\",\n",
        "    \"Benign Tumors\"\n",
        "]\n",
        "selected_classes_for_augmentation = [\"Psoriasis\", \"Fungal Infections\", \"Melanoma\"]\n",
        "\n",
        "# Assuming train_df and test_df are provided as Pandas DataFrames\n",
        "target_size = max(train_df[\"class_name\"].value_counts())  # Target number of images per class\n",
        "train_balanced_dataset = BalancedDataset(train_df, selected_classes_for_augmentation, target_size)\n",
        "test_balanced_dataset = BalancedDataset(test_df, selected_classes_for_augmentation, target_size)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_balanced_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_balanced_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load pre-trained InceptionV3 model\n",
        "model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modify the fully connected layer to match the number of classes\n",
        "num_classes = len(selected_classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model.aux_logits = True  # Enable auxiliary classifier for training\n",
        "\n",
        "# Move the model to the selected device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the training loop\n",
        "def train(model, train_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for images, labels in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs, aux_outputs = model(images)\n",
        "            loss1 = criterion(outputs, labels)\n",
        "            loss2 = criterion(aux_outputs, labels)\n",
        "            loss = loss1 + 0.4 * loss2\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            tepoch.set_postfix(loss=running_loss / (total / train_loader.batch_size), accuracy=accuracy)\n",
        "\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "# Define the validation loop\n",
        "def validate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss / len(test_loader), accuracy\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = validate(model, test_loader, criterion)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"inceptionv3_balanced_model.pth\")\n",
        "print(\"\\nModel saved as 'inceptionv3_balanced_model.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPzpeOl9b13_",
        "outputId": "6fc37e17-a326-4d7d-c081-5f0f0157f962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 308/308 [02:16<00:00,  2.25batch/s, accuracy=59.7, loss=1.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.3961, Train Accuracy: 59.73%\n",
            "Validation Loss: 0.9308, Validation Accuracy: 62.75%\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=69.8, loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 1.0493, Train Accuracy: 69.79%\n",
            "Validation Loss: 1.1767, Validation Accuracy: 57.92%\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 308/308 [02:16<00:00,  2.26batch/s, accuracy=75.5, loss=0.862]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.8605, Train Accuracy: 75.47%\n",
            "Validation Loss: 0.8061, Validation Accuracy: 69.78%\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=80, loss=0.722]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.7206, Train Accuracy: 79.97%\n",
            "Validation Loss: 0.7403, Validation Accuracy: 72.35%\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 308/308 [02:15<00:00,  2.28batch/s, accuracy=82.2, loss=0.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.6284, Train Accuracy: 82.25%\n",
            "Validation Loss: 0.7098, Validation Accuracy: 70.81%\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=84.4, loss=0.561]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 0.5595, Train Accuracy: 84.39%\n",
            "Validation Loss: 0.6581, Validation Accuracy: 74.56%\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 308/308 [02:17<00:00,  2.25batch/s, accuracy=86.5, loss=0.476]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss: 0.4747, Train Accuracy: 86.49%\n",
            "Validation Loss: 1.0275, Validation Accuracy: 69.14%\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 308/308 [02:16<00:00,  2.26batch/s, accuracy=88, loss=0.441]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss: 0.4397, Train Accuracy: 87.98%\n",
            "Validation Loss: 0.7916, Validation Accuracy: 73.55%\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 308/308 [02:16<00:00,  2.25batch/s, accuracy=89.5, loss=0.394]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss: 0.3927, Train Accuracy: 89.53%\n",
            "Validation Loss: 0.7593, Validation Accuracy: 75.43%\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 308/308 [02:16<00:00,  2.26batch/s, accuracy=90.5, loss=0.346]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss: 0.3450, Train Accuracy: 90.46%\n",
            "Validation Loss: 0.8608, Validation Accuracy: 74.70%\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=90.8, loss=0.347]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss: 0.3459, Train Accuracy: 90.81%\n",
            "Validation Loss: 0.6628, Validation Accuracy: 78.11%\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 308/308 [02:16<00:00,  2.26batch/s, accuracy=92, loss=0.287]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss: 0.2862, Train Accuracy: 91.98%\n",
            "Validation Loss: 0.8464, Validation Accuracy: 75.17%\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 308/308 [02:16<00:00,  2.26batch/s, accuracy=92.6, loss=0.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss: 0.2692, Train Accuracy: 92.61%\n",
            "Validation Loss: 0.8062, Validation Accuracy: 75.73%\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 308/308 [02:16<00:00,  2.25batch/s, accuracy=92.1, loss=0.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss: 0.2994, Train Accuracy: 92.06%\n",
            "Validation Loss: 0.8483, Validation Accuracy: 74.72%\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=93.1, loss=0.262]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss: 0.2616, Train Accuracy: 93.10%\n",
            "Validation Loss: 0.9599, Validation Accuracy: 72.97%\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=93.1, loss=0.253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss: 0.2524, Train Accuracy: 93.12%\n",
            "Validation Loss: 0.8107, Validation Accuracy: 75.84%\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=94.9, loss=0.201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Loss: 0.2006, Train Accuracy: 94.94%\n",
            "Validation Loss: 0.8322, Validation Accuracy: 76.32%\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=95, loss=0.198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss: 0.1971, Train Accuracy: 95.01%\n",
            "Validation Loss: 1.0065, Validation Accuracy: 74.55%\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 308/308 [02:15<00:00,  2.27batch/s, accuracy=94.5, loss=0.216]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss: 0.2160, Train Accuracy: 94.52%\n",
            "Validation Loss: 0.7841, Validation Accuracy: 76.76%\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 308/308 [02:16<00:00,  2.26batch/s, accuracy=94.6, loss=0.207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss: 0.2061, Train Accuracy: 94.58%\n",
            "Validation Loss: 0.9118, Validation Accuracy: 74.95%\n",
            "\n",
            "Model saved as 'inceptionv3_balanced_model.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EFFICIENT NET"
      ],
      "metadata": {
        "id": "XtvoTsJ0dNcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if GPU is available; fall back to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define transformations for training and validation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize image to 224x224 (EfficientNet's default size)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize image to 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset Class\n",
        "class BalancedDataset(Dataset):\n",
        "    def __init__(self, dataframe, selected_classes_for_augmentation, target_size):\n",
        "        self.data = []\n",
        "        self.selected_classes = selected_classes_for_augmentation\n",
        "        self.target_size = target_size\n",
        "        self.class_counts = dataframe[\"class_name\"].value_counts()\n",
        "\n",
        "        for class_name, count in self.class_counts.items():\n",
        "            class_samples = dataframe[dataframe[\"class_name\"] == class_name]\n",
        "\n",
        "            # Oversample or undersample to match the target size\n",
        "            if count < self.target_size:\n",
        "                sampled_df = class_samples.sample(n=self.target_size, replace=True)  # Oversample\n",
        "            else:\n",
        "                sampled_df = class_samples.sample(n=self.target_size, replace=False)  # Undersample\n",
        "\n",
        "            self.data.append(sampled_df)\n",
        "\n",
        "        self.data = pd.concat(self.data).reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        image_path = row[\"image_path\"]\n",
        "        label = row[\"class_name\"]\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply augmentation only for selected classes\n",
        "        if label in self.selected_classes:\n",
        "            image = train_transform(image)\n",
        "        else:\n",
        "            image = test_transform(image)\n",
        "\n",
        "        # Convert label to index for PyTorch compatibility\n",
        "        label_index = selected_classes.index(label)\n",
        "\n",
        "        return image, label_index\n",
        "\n",
        "\n",
        "# Define the selected classes and target size for balancing\n",
        "selected_classes = [\n",
        "    \"Psoriasis\",\n",
        "    \"Fungal Infections\",\n",
        "    \"Melanoma\",\n",
        "    \"Nail Fungus\",\n",
        "    \"Acne\",\n",
        "    \"Warts\",\n",
        "    \"Benign Tumors\"\n",
        "]\n",
        "selected_classes_for_augmentation = [\"Psoriasis\", \"Fungal Infections\", \"Melanoma\"]\n",
        "\n",
        "# Assuming train_df and test_df are provided as Pandas DataFrames\n",
        "target_size = max(train_df[\"class_name\"].value_counts())  # Target number of images per class\n",
        "train_balanced_dataset = BalancedDataset(train_df, selected_classes_for_augmentation, target_size)\n",
        "test_balanced_dataset = BalancedDataset(test_df, selected_classes_for_augmentation, target_size)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_balanced_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_balanced_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load pre-trained EfficientNet model\n",
        "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modify the fully connected layer to match the number of classes\n",
        "num_classes = len(selected_classes)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "# Move the model to the selected device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the training loop\n",
        "def train(model, train_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for images, labels in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            tepoch.set_postfix(loss=running_loss / (total / train_loader.batch_size), accuracy=accuracy)\n",
        "\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "# Define the validation loop\n",
        "def validate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss / len(test_loader), accuracy\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 15\n",
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = validate(model, test_loader, criterion)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"efficientnet_b0_balanced_model.pth\")\n",
        "print(\"\\nModel saved as 'efficientnet_b0_balanced_model.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igbsKrnwUTbV",
        "outputId": "23963ce7-c095-4a61-caf9-a5c0ecf3baf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 308/308 [01:41<00:00,  3.04batch/s, accuracy=68.4, loss=0.804]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.8025, Train Accuracy: 68.37%\n",
            "Validation Loss: 0.6694, Validation Accuracy: 74.42%\n",
            "\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 308/308 [01:41<00:00,  3.05batch/s, accuracy=80.6, loss=0.506]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.5047, Train Accuracy: 80.58%\n",
            "Validation Loss: 0.6116, Validation Accuracy: 77.55%\n",
            "\n",
            "Epoch 3/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 308/308 [01:41<00:00,  3.05batch/s, accuracy=85.6, loss=0.373]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.3726, Train Accuracy: 85.63%\n",
            "Validation Loss: 0.6547, Validation Accuracy: 77.43%\n",
            "\n",
            "Epoch 4/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 308/308 [01:40<00:00,  3.05batch/s, accuracy=88.7, loss=0.302]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.3014, Train Accuracy: 88.65%\n",
            "Validation Loss: 0.5902, Validation Accuracy: 80.08%\n",
            "\n",
            "Epoch 5/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 308/308 [01:41<00:00,  3.02batch/s, accuracy=89.9, loss=0.283]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.2827, Train Accuracy: 89.93%\n",
            "Validation Loss: 0.6990, Validation Accuracy: 77.61%\n",
            "\n",
            "Epoch 6/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 308/308 [01:40<00:00,  3.05batch/s, accuracy=91.4, loss=0.228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 0.2277, Train Accuracy: 91.44%\n",
            "Validation Loss: 0.6385, Validation Accuracy: 80.04%\n",
            "\n",
            "Epoch 7/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 308/308 [01:41<00:00,  3.02batch/s, accuracy=92.9, loss=0.198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss: 0.1978, Train Accuracy: 92.86%\n",
            "Validation Loss: 0.6962, Validation Accuracy: 80.03%\n",
            "\n",
            "Epoch 8/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 308/308 [01:41<00:00,  3.03batch/s, accuracy=93.4, loss=0.186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss: 0.1852, Train Accuracy: 93.37%\n",
            "Validation Loss: 0.6158, Validation Accuracy: 83.02%\n",
            "\n",
            "Epoch 9/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 308/308 [01:41<00:00,  3.04batch/s, accuracy=93.8, loss=0.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss: 0.1699, Train Accuracy: 93.84%\n",
            "Validation Loss: 0.6525, Validation Accuracy: 82.49%\n",
            "\n",
            "Epoch 10/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 308/308 [01:41<00:00,  3.03batch/s, accuracy=95, loss=0.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss: 0.1398, Train Accuracy: 95.01%\n",
            "Validation Loss: 0.6913, Validation Accuracy: 80.08%\n",
            "\n",
            "Epoch 11/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 308/308 [01:41<00:00,  3.03batch/s, accuracy=94.6, loss=0.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss: 0.1499, Train Accuracy: 94.55%\n",
            "Validation Loss: 0.6650, Validation Accuracy: 81.50%\n",
            "\n",
            "Epoch 12/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 308/308 [01:41<00:00,  3.02batch/s, accuracy=95.5, loss=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss: 0.1313, Train Accuracy: 95.48%\n",
            "Validation Loss: 0.6868, Validation Accuracy: 81.76%\n",
            "\n",
            "Epoch 13/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 308/308 [01:41<00:00,  3.05batch/s, accuracy=96, loss=0.117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss: 0.1168, Train Accuracy: 95.97%\n",
            "Validation Loss: 0.7636, Validation Accuracy: 81.56%\n",
            "\n",
            "Epoch 14/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 308/308 [01:41<00:00,  3.05batch/s, accuracy=96.1, loss=0.123]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss: 0.1232, Train Accuracy: 96.11%\n",
            "Validation Loss: 0.7275, Validation Accuracy: 81.48%\n",
            "\n",
            "Epoch 15/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 308/308 [01:41<00:00,  3.05batch/s, accuracy=95.9, loss=0.119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss: 0.1190, Train Accuracy: 95.87%\n",
            "Validation Loss: 0.6161, Validation Accuracy: 82.33%\n",
            "\n",
            "Model saved as 'efficientnet_b0_balanced_model.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-2N4KYFspKR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}